# -*- coding: utf-8 -*-
"""Co_occurance matrix

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ypIjMCuVyGe79uFytHj4oxxaoQB0L-eN
"""

## Co occurance matrix for following corpus of window size 2
vocab=['He','is','not','lazy','smart','intelligent']
corpus='He is not lazy He is intelligent He is smart'

strt=time()
lst=np.array(corpus.split())
lenth=len(lst)
window=2
mn_dct={}
for i,word in enumerate(vocab):
    
  index=np.where(lst==word)[0]
  mn_dct[word]=dict.fromkeys(vocab,0)

  cntr=Counter()  
  for indx in index:
    cntr.update(Counter(lst[max(0,indx-window):min(lenth,indx+window+1)]))
  cntr[word]=0  
  mn_dct[word].update(cntr)
'''
Output:
  array([[0., 4., 2., 1., 1., 2.],
       [4., 0., 1., 2., 1., 2.],
       [2., 1., 0., 1., 0., 0.],
       [1., 2., 1., 0., 0., 0.],
       [1., 1., 0., 0., 0., 0.],
       [2., 2., 0., 0., 0., 0.]])

'''
## Making Co-Variance matrix ##
vocab_mtrx_svd=np.zeros((len(vocab),len(vocab)))
for i in range(len(vocab)):
  vocab_mtrx_svd[i,:]=np.array(list((mn_dct[vocab[i]].values())))

#vocab_mtrx_svd=vocab_mtrx_svd+vocab_mtrx_svd.transpose()

end=time()
print('Time elapsed: ',(end-strt)/60,' Minutes')
pd.DataFrame(vocab_mtrx_svd,index=vocab,columns=vocab)

## with counter
def prllell(wrds,npr=0):
  if npr==0: print('with counter')
  
  chk=len(wrds)
  mn_dct={}
  for i,word in enumerate(wrds):
    index=np.where(lst==word)[0]
    if i==0      :print(' '*(npr*20),'Processer no:',npr+1)
    if i%50==0   :print(' '*(npr*20),i,'words done')
    if i==chk-1  :print(' '*(npr*20),'Work of Processor %d done'%(npr+1))
        
    mn_dct[word]=dict.fromkeys(vocab,0)

    cntr=Counter()  
    for indx in index:
      cntr.update(Counter(lst[max(0,indx-window):min(lenth,indx+window+1)]))  ## In counter count of all words even which are not in our vocab, hence len of cntr dict is different size of vocab
                                                                                                
    cntr[word]=0  
    mn_dct[word].update(cntr)

  return mn_dct

vocab=top_wrds_2k_idf
corpus=' '.join(data_train.preprocessed_essay)

strt=time()
lst=np.array(corpus.split())
lenth=len(lst)
window=5

pool = mp.Pool()
res={}
no_prcss= mp.cpu_count()
nn=int(len(vocab)/no_prcss)
for i in range(no_prcss):
  res[i]=pool.apply_async(prllell,args=(vocab[i*nn:(i+1)*nn],i))
pool.close()
pool.join() 
mn_dct={}
for i in range(no_prcss):
  mn_dct.update(res[i].get())
if len(vocab)/no_prcss!=0 : mn_dct.update(prllel(vocab[(no_prcss+1)*nn:]))
end=time()
print('Time elapsed: ',(end-strt)/60,' Minutes')

## Making Co-Variance matrix ## with counter
vocab_len=len(vocab)
vocab_mtrx_svd=np.zeros((vocab_len,vocab_len))
for i in range(len(vocab)):
  vocab_mtrx_svd[i,:]=np.array(list((mn_dct[vocab[i]].values()))[:vocab_len])